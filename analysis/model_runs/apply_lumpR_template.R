# This file apply_lumpR_template.R is part of the analysis scripts for the paper Pilz et al. (2017), GMD
# Copyright (C) 2017 Tobias Pilz
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.





# This script was used to
#  1. do all initialisations of experimnents
#  2. produce landscape discretisations
#  3. run WASA with all landscape discretisations
#
# ATTENTION: Running this script takes a lot of time and memory. It has been run on a high performance computer using
# ~100 CPU cores and should not be run on a PC. This script on github is thus JUST FOR DEMONSTRATIONS / CONFIRMABILITY!
# The script may, however, be used as a guide to apply the lumpR package along with the WASA model.
# Script has to be run under LINUX ONLY (library doMC only works under Linux).
#
# Calculations for the paper are based on WASA rev. 247, repository date 2016-09-29 15:08:15 +0200 , built Di 18. Okt 15:00:13 CEST 2016
# WASA can be obtained free of charge upon request: http://www.uni-potsdam.de/sesam/svn_form.php


### SETTINGS ##################################################################
#
# make adjustments within this section
#
###############################################################################

# load library
library(LUMP) # LUMP package from https://github.com/tpilz/LUMP (install via install_github())
library(geostat) # package for inverse-distance interpolation by David Kneis from https://github.com/echse/echse_tools; close directory and extract this package (there are many software packages included)
library(doMC) # simplified parallelisation; Linux ONLY!
registerDoMC(cores=NCORES) # adjusted automatically by job-script

# switch to specified working directory
setwd("/mnt/scratch/users/stud06/tpilz/LUMP_paper/discretisations/") #use "/" instead of "\" in Windows

# output prefix
# output directory is: <getwd()>/<out_pref>_s<thresh_sub>_eha<eha_thres>_lunum<no_lus>_luatts<no_atts>_tc<no_tcs>
# name of database, GRASS mapset etc. is: <out_pref>_s<thresh_sub>_eha<eha_thres>_lunum<no_lus>_luatts<no_atts>_tc<no_tcs>
out_pref <- "lump_paper"

# ODBC Database: script will use the configuration file $HOME/.odbc.ini to register a database <getwd()>/<out_pref>_s<thresh_sub>_eha<eha_thres>_lunum<no_lus>_luatts<no_atts>_tc<no_tcs>/database/dbase.db
# specify your registered ODBC driver name
odbc_driver <- "myodbc_sqlite3"
# server name for ODBC
odbc_servername <- "localhost"


### INPUT ###
# inputs marked MANDATORY have to be given, the rest can be 'NULL' if not available

# shall strategic reservoir point be used as drainage points?
# if TRUE you don't need to specify drain_p (it will be overwritten)
drain_use_reservoirs <- T

# watershed outlet (coordinates in projection of GRASS location!) 
drain_p <- data.frame(utm_x_m=374036, utm_y_m=9270745) # outlet of Bengue reservoir
# specifiy columns containing coordinates
coordinates(drain_p) <- c("utm_x_m", "utm_y_m")

# which row contains the watershed outlet? (in drain_p order attribute table of strategic reservoir vector map res_strategic_vect)
outlet_point <- 1 # Bengue reservoir in strategic reservoirs attribute table

# DEM raster in GRASS location - MANDATORY
dem <- "dem@PERMANENT"

# land / vegetation cover raster map in GRASS location - MANDATORY
lcov <- "lcov@PERMANENT"

# soil raster map in GRASS location - MANDATORY
soil <- "soil@PERMANENT"

# soil depth raster map
soil_depth <- "soil_depth@PERMANENT"

# water mask raster map in GRASS location (1=water, 0=no water)
watermask <- "watermask@PERMANENT"

# impervious surface areas raster map in GRASS location (1=impervious, 0=permeable)
imperviousmask <- NULL

# river vector map
river <- NULL

# vector map of reservoirs to be classified for treatment as lumped reservoirs in WASA using reservoir_lumped() - MANDATORY
# Has to be a point instead of a polygon vector map! Consider function reservoir_outlet().
# Needs column 'area' (maximum lake area in m2) and/or 'volume' (maximum lake volume in m3) in attribute table
res_lumped_vect <- "reservoirs_lump@PERMANENT"

# vector map of reservoirs to be classified for treatment as strategic reservoirs in WASA using reservoir_strategic() - MANDATORY
# Has to be a point instead of a polygon vector map! Consider function reservoir_outlet(). Reservoir outlet should be the outlet
# of a subbasin as in the WASA model strategic reservoirs are generally assumed to be at the subbasin's outlet.
# Needs to have some mandatory columns in the attribute table, see ?reservoir_strategic
res_strategic_vect <- "reservoir_strategic_Bengue@PERMANENT"
#res_strategic_vect <- "reservoir_strategic_Bengue@reservoirs"

# meteo time series files
# columns in files have to be stations as defined in location files (see below)
# grid-based (Xavier)
# needed variables for WASA: precipitation, temperature, relative humidity, short-wave incoming radiation - MANDATORY
meteo_ts <- c(prec = "/users/stud06/tpilz/LUMP/input/meteo/ts_prec.dat",
              relhum = "/users/stud06/tpilz/LUMP/input/meteo/ts_RH.dat",
              temper = "/users/stud06/tpilz/LUMP/input/meteo/ts_Tmean.dat",
              glorad = "/users/stud06/tpilz/LUMP/input/meteo/ts_glorad.dat")

# meteo data location for interpolation - MANDATORY
# named vector of location files for each variable, see ?externalInputLocationsTable 'files_sources'
meteo_locs <- c(prec = "/users/stud06/tpilz/LUMP/input/meteo/locs.dat",
                relhum = "/users/stud06/tpilz/LUMP/input/meteo/locs.dat",
                temper = "/users/stud06/tpilz/LUMP/input/meteo/locs.dat",
                glorad = "/users/stud06/tpilz/LUMP/input/meteo/locs.dat")

# file of extraterrestrial radiation for the whole watershed area (already in WASA format)
radex_file <- "/users/stud06/tpilz/LUMP/input/meteo/extraterrestrial_radiation.dat"

# path to prepared vegetation parameter table 'vegetation.dat' in WASA format - MANDATORY
veg_path <- "/users/stud06/tpilz/LUMP/input/vegetation/"

# path to prepared soil parameter tables 'horizons.dat, 'particle_classes.dat', 'r_soil_contains_particles.dat', and 'soil.dat' in WASA format - MANDATORY
soil_path <- "/users/stud06/tpilz/LUMP/input/soil/"



### OUTPUT ###
# outputs marked MANDATORY have to be given, the rest can be 'NULL'
# some outputs are inputs for other functions (e.g. flow accumulation)

# subbasin raster map - MANDATORY
subbas <- "subbas"

# prefix of calculated stream segments raster and vector maps
stream_pref <- "stream_accum"

# prefix of drainage point vector files (given points snapped to river and internally calculated points, respectively) - MANDATORY
drainp_processed <- "drain_points"

# elementary hillslope areas raster map - MANDATORY
eha <- "eha"

# flow direction raster map - MANDATORY
flowdir <- "flowdir"

# flow accumulation raster map - MANDATORY
flowacc <- "flowacc"

# stream segments raster map (based on eha calculation; much finer than 'stream_pref' to delineate hillslopes) - MANDATORY
stream <- "stream"

# Horton stream order raster map (based on 'stream' above) - MANDATORY
stream_horton <- "stream_horton"

# elevation relative to next river segment raster map - MANDATORY
elevriv <- "elevriv"

# distance to next river segment raster map - MANDATORY
distriv <- "distriv"

# soil vegetation components raster map - MANDATORY
svc <- "svc"

# landscape units raster map - MANDATORY
lu <- "lu"

# name of file containing svc parameters - MANDATORY
svc_file <- "soil_vegetation_components.dat"

# Name of output file containing mean catena information as input for prof_class - MANDATORY
catena_out <- "rstats.txt"

# Name of output header file containing meta-information as input for prof_class - MANDATORY
catena_head_out <- "rstats_head.txt"

# Name of subbasin statistics file containing subbasin parameters
sub_ofile <- "sub_stats.txt"

# Name of file containing subbasins and the corresponding LUs with their fraction of area in the subbasin
lu_ofile <- "lu_stats.txt"

# Name of file containing LUs and related parameters
lupar_ofile <- "lu_pars.txt"

# Name for the vector reservoir map created in GRASS location containing information on reservoir size classes in the attribute table
# If NULL it will not be created
res_vect_class <- "res_vect_class"



### PARAMETERS ###


# MISCELLANEOUS PARAMETERS #
# parameters influecing some outputs but not directly discretisation complexity

# Raster cells in accumulation map with values greater than thresh_stream are considered as streams. Needs to be set only if river is not set - MANDATORY
thresh_stream <- 1000

# maximum distance for snapping of drain_points to stream segments in units of your GRASS location - MANDATORY
snap_dist <- 500

# shall small spurious subbasins created within calc_subbas() be deleted? (automatically set to FALSE if drain_use_reservoirs=TRUE)
rm_spurious <- T

# minimum size of EHAs (in map units) not to be removed, smaller EHAs (artefacts) are removed; parameter for GRASS function r.reclass.area - MANDATORY
sizefilter <- 30 

# growing radius (in raster cells) to remove artefacts in EHA data; parameter for GRASS function r.grow - MANDATORY
growrad <- 50

# minimum number of cells a hillslope area must have, all smaller ones are skipped
min_cell_in_slope <- 10

# minimum number of sampling points (cells) a catena should have. If there are less, the catena is not saved
min_catena_length <- 3

# maximum distance to river [in cells]: if the closest cell of an EHA is farther than max_riv_dist, the EHA is skipped, otherwise all distances within the EHA are redurced by the distance of the closest cell to river
max_riv_dist <- 15

# lumped reservoir parameters, see ?reservoir_lumped
res_lumped_pars <- data.frame(class=1:5,
                              vol_max=c(5000,25000,50000,100000,15000000),
                              f_vol_init=0.2,
                              class_change=0,
                              alpha_Molle=2.7,
                              damk_Molle=1500,
                              damc_hrr=c(7,14,21,28,35),
                              damd_hrr=1.5)


# RUN TIME PARAMETERS #

# shall temporary files be kept in the GRASS location, e.g. for debugging or further analyses?
keep_temp <- F

# Shall output of previous calls of this function be deleted? If FALSE the function returns an error if output already exists
overwrite <- T

# Shall the function be silent (also suppressing warnings of internally used GRASS functions, etc.)?
silent <- T

# produce plots (scatter, mean catena, etc.) for each area / class (written into sub-directory plots_area2catena)
plot_catena <- F

# produce plots of classification of catenas to landscape units and terrain components
plot_profclass <- F

# produce GRASS reclassification files for qualitative raster data
grass_files <- F

# number of cores that should be used for parallel computation (where possible)
ncores <- 1


# WASA SIMULATION PARAMETERS #

# WASA simulation directory: sub-directory 'dbname' containing simulation input and output will be created
wasa_sim_dir <- "../model_runs/"

# simulation start year (first) and month (second element)
sim_start <- c(2001, 1)
# simulation end year (first) and month (second element)
sim_end <- c(2013, 12)

# shall strategic reservoirs be simulated by WASA?
do_res_strategic <- T
# cav file for strategic reservoirs if available (otherwise set to NULL)
cav_file <- "/users/stud06/tpilz/LUMP/input/reservoir/cav.dat"

# shall lumped reservoirs be simulated by WASA?
do_res_lump <- T

# shall WASA's state variables be written as output for further analysis?
save_wasa_states <- T

# vector of output files to be created (NULL means standard WASA output)
wasa_out_files <- c("River_flow", "res_watbal", "daily_water_subbasin", "lake_watbal", "daily_actetranspiration")

# WASA model application (set NULL if the model shall not be run; include path to application if not set as global environment variable or within a 'PATH' directory)
wasa_app <- "WASA"



# LANDSCAPE DISCRETISATION PARAMETERS #

# parameters into a list to determine parameter combinations from sampling vectors for each parameter (specify exactly two values (min and max) for every parameter!)
params <- list(
  # Parameter for GRASS function r.watershed defining the minimum size of an exterior watershed basin in number of grid cells. If NULL only the given drainage points are used for subbasin delineation - MANDATORY
  thresh_sub =  c(1000, # 57 subbasins
                  2000, # 20 subbasins
                  5000, # 10 subbasins
                  10000, # 7 subbasins
                  30000), # 1 subbasin
  
  # parameter for GRASS function r.watershed. This is a crucial parameter affecting the size of delineated hillslopes - MANDATORY
  eha_thres =  c(25, # 826 EHAs (many are discarded for being too small, having not enough sample points)
                 50, # 1132 EHAs
                 100, # 906 EHAs
                 200, # 530 EHAs
                 500, # 220 EHAs
                 750, # 147 EHAs
                 1000), # 115 EHAs
  
  # potential maximum number of LUs to be generated (actual number may be lower after classification process; see prof_class())
  no_LUs = c(5,10,20,50,75,100,150,200,250,300),
  
  # number of attributes to be used for LU generation
  # maximum no depends on available supplemental information: shape + extent + supplemental information + slope_width
  no_atts = c(1:7),
  
  # number of TCs that are created by algorithm (numTC)
  cTC1 = c(1:5)
)

# Latin hypercube sampling of parameter space; first argument defines sampling size, i.e. no. of discretisations
# lhs_sample <- randomLHS(10, length(params))
# combinations <- data.frame(matrix(NA, nrow=nrow(lhs_sample), ncol=length(params), dimnames=list(NULL, names(params))))
# for (s in 1:length(params))
#   combinations[,names(params)[s]] <- ceiling(qunif(lhs_sample[,s], params[[s]][1]-1, params[[s]][2]))
combinations <- expand.grid(params)

# landscape attributes (partly dynamical based on no_LUs and no_atts)
LANDSCAPE_ATTRIBUTES <- list(
  
  # 1: Specifying the overall number of classes and weighting factor for each attribute (not supported anymore!)
  #-1: Specifying the number of classes applied to each single attribute. The final classification results from the intersection of the classification for each single attribute.
  CLASSIFICATION_METHOD=-1,
  
  # lu_class:  weighting factor / number of LU-classes to generate for this attribute (value 1 treated the same way as 0 within prof_class())
  # tc_class:  weighting factors (relative to slope) for the respective attribute used  in TC-partitioning
  # type:      "quant" for numerical data, "qual" for categorical data
  
  # weighting factor of vertical extension, relative to horizontal-weighting
  # static in this context
  weight_ext = list(lu_class=10, tc_class=0, type=""),
  
  # number of classes to be generated based on shape
  shape = list(lu_class=rep(1, nrow(combinations)),
               tc_class=combinations$cTC1,
               type=""),
  
  # number of classes to be generated based on horizontal AND vertical extension
  ext = list(lu_class=rep(1, nrow(combinations)),
             tc_class=0,
             type=""),
  
  # supplemental information and their weights/class no. in the classification of hillslopes
  # name:      name of raster map in GRASS
  "soil@PERMANENT" = list(lu_class=rep(1, nrow(combinations)),
                          tc_class=0,
                          type="qual"),
  "geology@PERMANENT" = list(lu_class=rep(1, nrow(combinations)),
                             tc_class=0,
                             type="qual"),
  "lcov@PERMANENT" = list(lu_class=rep(1, nrow(combinations)),
                          tc_class=0,
                          type="qual"), 
  #do not remove this one, only adjust lu_class and tc_class
  # slope_width: calculated by area2catena ("density") -> for specific profile point: number of sampling points for this profile point / total number of hillslope sampling points
  "slope_width" = list(lu_class=rep(1, nrow(combinations)),
                       tc_class=0,
                       type=""),
  # ALWAYS has to be defined to generate SVC parameters needed for WASA! Map is generated by lump_grass_prep().
  "svc" = list(lu_class=rep(1, nrow(combinations)),
               tc_class=0,
               type="qual")
)

# sample attribute realisations depending on current combinations$no_atts and combinations$no_LUs
atts_realis <- apply(combinations[,c("no_LUs", "no_atts")], 1, function(x) { 
  # sample attributes
  atts <- sort(sample(params$no_atts, x["no_atts"]))
  
  # stepwise random increase of LUs to be generated for each attribute until no_LUs is reached
  lus <- rep(1, length(atts))
  while(prod(lus) < x["no_LUs"]) {
    ind <- sample(length(atts), 1)
    lus[ind] <- lus[ind] + 1
  }
  
  return(list(atts=atts,lus=lus))
})

# relate atts_realis to LANDSCAPE_ATTRIBUTES ('lu_class')
for (i in 1:length(atts_realis)) {
  for (j in 1:length(atts_realis[[i]]$atts)) {
    LANDSCAPE_ATTRIBUTES[[atts_realis[[i]]$atts[j]+2]]$lu_class[i] <- atts_realis[[i]]$lus[j]
  }
}

# loop over combinations (still within settings!)
logdata <- foreach (combi = 1:nrow(combinations), .combine=rbind, .options.multicore=list(silent=FALSE), .errorhandling = "remove",
                    .inorder=FALSE) %dopar% {
  
  # GRASS SESSION #
  # name of the database registered at ODBC source
  # database file will be created in sub-dir "database"
  dbname <- paste0(out_pref, "_s", combinations$thresh_sub[combi], "_eha", combinations$eha_thres[combi], 
                   "_lunum", combinations$no_LUs[combi], "_luatts", combinations$no_atts[combi],
                   "_tc", combinations$cTC1[combi])   
  
  # output directory
  output_dir <- paste(getwd(), dbname, sep="/")
  
  # create temporary directory for GRASS
  grass_tmpdir <- paste0(output_dir, "/", "grass_tempdir_", combi)
  dir.create(grass_tmpdir, recursive = T, showWarnings = F)
  
  # path to your locally installed GRASS add-ons. Must only be given if necessary, see function doc
  addon_path="/users/stud06/tpilz/.grass6/addons/"
  # initialisation of session
  initGRASS(gisBase="/users/stud06/tpilz/usr/local/grass-6.4.6", # path to GRASS installation (use / instead of \ under windows, e.g. "d:/programme/GRASS6.4.3" )
            home=grass_tmpdir, # The directory in which to create the .gisrc file
            location="Bengue", # GRASS location
            mapset=dbname,    # corresp. mapset
            gisDbase="/mnt/scratch/users/stud06/tpilz/grassdata/",  # path to grass data directory containing the location specified above and all corresp. data
            override=TRUE)
  
  
  
  
  
  ### CALCULATIONS ##############################################################
  #
  # - no adjustments necessary
  # - keeps track of time for landscape discretisation and model simulation
  #
  # Includes the following steps:
  #   - Subbasins delineation
  #   - Pre-processing and hillslope deviation
  #   - Calculation of hillslope properties
  #   - Classification of hillslopes into Landscape Units and Terrain Components
  #   - Post-processing
  #   - Preparation of meteorological data (interpolation, formatting, etc.)
  #   - Calculation of rainy season statistics
  #   - Reservoir parameterisation
  #   - Parameter database (generation, checking, creation of WASA input files)
  #   - Model initialisation and run
  #
  ###############################################################################
  
  
  tryCatch({
    
    
    # keep track of pre-processing time
    prep_time <- system.time({
      
      
      # SUBBASIN DELINEATION #
      
      if(drain_use_reservoirs) {
        # read strategic reservoir outlet locations as drainage points
        drain_p <- readVECT6(res_strategic_vect)
        projection(drain_p) <- getLocationProj()
        rm_spurious <- F
      } else {
        # define projection of drainage point(s) (use projection of GRASS location)
        projection(drain_p) <- getLocationProj()
      }
      
      # calculate subbasins; one subbasin for each drainage point
      calc_subbas(
        # INPUT #
        dem=dem,
        drain_points=drain_p,
        river=river,
        # OUTPUT #
        basin_out=subbas,
        stream=stream_pref,
        points_processed=drainp_processed,
        # PARAMETERS #
        outlet=outlet_point,
        thresh_stream=thresh_stream,
        thresh_sub=combinations$thresh_sub[combi],
        snap_dist=snap_dist,
        rm_spurious=rm_spurious,
        keep_temp=keep_temp,
        overwrite=overwrite,
        silent=silent
      )
      
      
      
      # PREPROCESSING AND HILLSLOPE DEVIATION #
      lump_grass_prep(
        # INPUT #
        mask = subbas,
        dem = dem,
        lcov = lcov,
        soil = soil,
        watermask = watermask,
        imperviousmask = imperviousmask,
        # OUTPUT #
        eha=eha,
        flowdir = flowdir,
        flowacc = flowacc,
        stream = stream,
        stream_horton = stream_horton,
        elevriv = elevriv,
        distriv = distriv,
        mask_corr = "MASK_corr",
        svc = svc,
        dir_out = output_dir,
        svc_ofile = svc_file,
        # PARAMETERS #
        eha_thres = combinations$eha_thres[combi],
        sizefilter = sizefilter,
        growrad = growrad,
        keep_temp=keep_temp,
        overwrite=overwrite,
        silent=silent,
        addon_path=addon_path
      )
      
      
      
      # CALCULATE MEAN CATENA FOR HILLSLOPES #
      # get names of supplemental quant. and qual. data
      suppl_sel <- sapply(LANDSCAPE_ATTRIBUTES[-1], function(x) if(x["type"] == "qual") return(1) else if(x["type"] == "quant") return(2) else return(0))
      SUPP_QUAL  = names(suppl_sel)[which(suppl_sel==1)]
      SUPP_QUANT = names(suppl_sel)[which(suppl_sel==2)]
      
      # assemble header for rstats_header; order of values in important (should follow catena_head_out)
      lu_classes_t <- sapply(LANDSCAPE_ATTRIBUTES[-1], function(x) if(length(x[["lu_class"]]) == 1) x[["lu_class"]] else x[["lu_class"]][combi])
      lu_classes_t["shape"] <- lu_classes_t["shape"] * LANDSCAPE_ATTRIBUTES$CLASSIFICATION_METHOD
      tc_classes_t <- sapply(LANDSCAPE_ATTRIBUTES[-1], function(x) if(length(x[["tc_class"]]) == 1) x[["tc_class"]] else x[["tc_class"]][combi])
      rstats_header =  list(lu_class=lu_classes_t[c("shape", "ext", "weight_ext", SUPP_QUANT, SUPP_QUAL, "slope_width")],
                            tc_class=tc_classes_t[c("shape", "ext", "weight_ext", SUPP_QUANT, SUPP_QUAL, "slope_width")])
      
      # area2catena: calculate hillslope properties of EHAs #
      # Part of algorithm described by Francke et al. (2008)
      area2catena(
        # INPUT #
        mask="MASK_corr",
        flowacc=flowacc,
        eha=eha,
        distriv=distriv,
        elevriv=elevriv,
        supp_quant=SUPP_QUANT,
        supp_qual=SUPP_QUAL,
        # OUTPUT #
        dir_out=output_dir,
        catena_out=catena_out,
        catena_head_out=catena_head_out,
        # PARAMETERS #
        ridge_thresh=1,
        min_cell_in_slope=min_cell_in_slope,
        min_catena_length=min_catena_length,
        max_riv_dist=max_riv_dist,
        plot_catena=plot_catena,
        grass_files=grass_files,
        ncores=ncores,
        eha_subset=NULL,
        overwrite=overwrite,
        silent=silent
      )
      
      # change header file according to rstats_header
      header_dat <- readLines(paste(output_dir, catena_head_out, sep="/"))
      header_dat[8] <- paste(rstats_header$lu_class, "\t", sep="", collapse="")
      header_dat[9] <- paste(rstats_header$tc_class, "\t", sep="", collapse="")
      writeLines(header_dat,paste(output_dir, catena_head_out, sep="/"))
      
      
      
      # CATENA CLASSIFICATION INTO LANDSCAPE UNITS AND TERRAIN COMPONENTS #
      # Part of algorithm described by Francke et al. (2008)
      # get resolution (mean between x and y resolution)
      res <- execGRASS("r.info", map=dem, flags=c("s"), intern=TRUE)
      res <- sum(as.numeric(gsub("[a-z]*=", "", res))) / 2
      
      prof_class(
        # INPUT #
        catena_file=paste(output_dir,catena_out,sep="/"),
        catena_head_file=paste(output_dir,catena_head_out,sep="/"),
        svc_column="svc",
        # OUTPUT #
        dir_out=output_dir,
        luoutfile="lu.dat",
        tcoutfile="tc.dat",
        lucontainstcoutfile="lucontainstc.dat",
        tccontainssvcoutfile="tc_contains_svc.dat",
        terraincomponentsoutfile="terraincomponents.dat",
        recl_lu="reclass_lu.txt",
        saved_clusters="cluster_centers.Rdat",
        # PARAMETERS #
        seed=1312,
        resolution=res,
        classify_type=' ',
        max_com_length=50,
        com_length=NULL,
        make_plots=plot_profclass,
        eha_subset=NULL,
        overwrite=overwrite,
        silent=silent
      )
      
      
      
      # POST PROCESSING #
      lump_grass_post(
        # INPUT #
        mask = "MASK_corr",
        dem = dem,
        recl_lu = paste(output_dir, "reclass_lu.txt", sep="/"),
        lu = lu,
        subbasin = subbas,
        eha = eha,
        flowacc = flowacc,
        flowdir = flowdir,
        stream_horton = stream_horton,
        soil_depth = NULL,
        sdr=NULL,
        # OUTPUT #
        dir_out = output_dir,
        sub_ofile = sub_ofile,
        lu_ofile = lu_ofile,
        lupar_ofile = lupar_ofile,
        # PARAMETER #
        fill_holes=T,
        groundwater=0,
        keep_temp = keep_temp,
        overwrite = overwrite,
        silent = silent
      )
      
      
      
      # METEO DATA PREPARATION #
      # interpolation of meteo data from prepared raw data (time series and location definition file for every variable)
      # output to meteo/ are WASA input files ready to use
      dir.create(paste(output_dir,"rainy_season/", sep="/"))
      dir.create(paste(output_dir,"meteo/", sep="/"))
      # calculate weights for precipitation interpolation to subbasin centroids
      externalInputLocationsTable(file_targets= paste(output_dir,sub_ofile,sep="/"), 
                                  files_sources= meteo_locs,
                                  idField_targets="pid", idField_sources="id", colsep = "\t", nsectors = 4, norigins = 4, power = 2,
                                  file_result= paste(output_dir,"meteo/weights.dat",sep="/"), ndigits = 3, overwrite = T)
      
      # read weights data
      dat_wgt <- read.table(paste(output_dir,"meteo/weights.dat",sep="/"), header = T, sep = "\t")
      
      # read catchment data
      dat_cat <- read.table(paste(output_dir,sub_ofile,sep="/"), header = T)
      
      # loop over variables
      for (v in names(meteo_ts)) {
        
        # read ts data
        dat_ts <- read.zoo(meteo_ts[v], header=T, sep="\t")
        
        # remove leading "X" in colnames if present
        colnames(dat_ts) <- gsub("^X", "", colnames(dat_ts))
        
        # get relevant weight data
        var_wgt <- dat_wgt[grep(v, dat_wgt$variable),]
        
        # loop over target stations
        dat_interp <- NULL
        for (s in 1:nrow(dat_cat)) {
          
          # target location
          stat_tar <- dat_cat$pid[s]
          
          # get relevant rows in weight table
          rows_wgt <- which(var_wgt$object == stat_tar)
          
          # get relevant stations from ts data
          dat_t <- dat_ts[,as.character(var_wgt$location[rows_wgt]), drop=F]
          weights_s <- var_wgt$weight[rows_wgt]
          
          # compute weighted mean
          dat_interp_t <- apply(dat_t, 1, function(x,w=weights_s) sum(x*w))
          
          # combine output
          dat_interp <- cbind(dat_interp, dat_interp_t)
          
        } # loop over stations
        
        # xts object for interpolated precipitation
        dat_interp_xts <- xts(dat_interp, index(dat_ts))
        colnames(dat_interp_xts) <- dat_cat$pid
        
        # wasa time series input file structure
        wasa_out <- format(index(dat_interp_xts), "%d%m%Y")
        wasa_out <- cbind(wasa_out, 1:length(wasa_out))
        wasa_out <- cbind(wasa_out, round(coredata(dat_interp_xts),1))
        colnames(wasa_out) <- c("0", "0", colnames(dat_interp_xts))
        
        # write output
        if (v == "prec") {
          write("Daily average precipitation [mm/d] for each subasin, ordered according to Map-IDs", paste(output_dir,"meteo/rain_daily.dat", sep="/"))
          wasa_name <- "rain_daily"
          dat_prec_interp_xts <- dat_interp_xts # needed later for rainy season
        }
        if (v == "temper") {
          write("Daily average temperature (in degree Celcius) for each subasin, ordered according to Map-IDs", paste(output_dir,"meteo/temperature.dat", sep="/"))
          wasa_name <- "temperature"
        }
        if (v == "relhum"){
          write("Daily average humidity [in %] for each subasin, ordered according to Map-IDs", paste(output_dir,"meteo/humidity.dat", sep="/"))
          wasa_name <- "humidity"
        }
        if (v == "glorad") {
          write("Daily average shortwave radiation [in W/m2] for each subasin, ordered according to Map-IDs", paste(output_dir,"meteo/radiation.dat", sep="/"))
          wasa_name <- "radiation"
        }
        
        write("Date  No. of days, Subasin-ID, Subasin-ID,...", paste0(output_dir, "/meteo/", wasa_name,".dat"), append=T)
        write.table(wasa_out, paste0(output_dir, "/meteo/", wasa_name,".dat"), col.names=T, row.names=F, append=T, quote=F, sep="\t")
        
      } # loop over variables
      
      
      
      # RAINY SEASON #
      # apply function to calculate start and end of rainy season
      dat_rainy <- rainy_season(dat_prec_interp_xts, 243, -9999)
      
      colnames(dat_rainy) <- c("subbas_id", "yearm", "node1", "node2", "node3", "node4")
      
      # make compliant with WASA parameter table
      dat_rainy <- cbind(pid=seq(1, nrow(dat_rainy)), dat_rainy, veg_id=rep(-1, nrow(dat_rainy)))
      
      # create output file
      write.table(dat_rainy, paste(output_dir,"rainy_season/rainy_season.csv", sep="/"), 
                  append=F, col.names=T, row.names=F, sep="\t", quote=F)
      
      
      
      # RESERVOIR DATA PREPARATION #
      # lumped reservoirs
      if(do_res_lump) {
        reservoir_lumped(
          # INPUT #
          res_vect = res_lumped_vect,
          sub_rast = subbas,
          # OUTPUT #
          res_vect_class = NULL,
          dir_out = paste(output_dir, "reservoir", sep="/"),
          lake_file = "lake.dat",
          lakenum_file = "lake_number.dat",
          # PARAMETER #
          res_param = res_lumped_pars,
          keep_temp = keep_temp,
          overwrite = overwrite,
          silent = silent
        )
      }
      
      # strategic reservoirs
      if(do_res_strategic) {
        # use 'points_processed' from calc_subbas() to use snapped instead of true locations for reservoir_strategic()
        points_snap <- readVECT6(paste(drainp_processed, "snap", sep="_"))
        res_strat <- readVECT6(res_strategic_vect)
        points_snap@data <- res_strat@data
        points_snap@data <- as.data.frame(lapply(points_snap@data, function(x) if(is.integer(x)) as.numeric(x) else x))
        colnames(points_snap@data) <- tolower(colnames(points_snap@data))
        writeVECT6(points_snap, "res_strat_snap_t")
        res_strategic_vect_t <- "res_strat_snap_t"
        
        # apply function
        reservoir_strategic(
          ### INPUT ###
          res_vect = res_strategic_vect_t,
          subbasin = subbas,
          ### OUTPUT ###
          dir_out = paste(output_dir, "reservoir", sep="/"),
          reservoir_file = "reservoir.dat",
          ### PARAMETER ###
          overwrite=overwrite,
          silent=silent
        )
        
        # remove temporary
        x <- execGRASS("g.remove", vect="res_strat_snap_t", intern=T)
      }
      
      
      
      # DATABASE #
      
      #     # database name must not be longer than 30 characters
      #     if(nchar(dbname) > 30) {
      #       db_name <- out_pref
      #       odbc_sources <- odbcDataSources()
      #       if(any(grepl(paste0("^",db_name,"$"), names(odbc_sources)))) {
      #         ith <- substr(grep(paste0("^", db_name), names(odbc_sources), value=T), nchar(db_name)+2, nchar(db_name)+2)
      #         if(any(!is.na(as.numeric(ith))))
      #           db_name <- paste(db_name, max(as.numeric(ith), na.rm = T)+1, sep="_")
      #         else
      #           db_name <- paste(db_name, "1", sep="_")
      #       }
      #     } else {
      #       db_name <- dbname
      #     }
      db_name <- paste(out_pref, combi, sep="_")
      # register database (write into .odbc.ini)
      str_odbc <- c(paste0("[", db_name, "]"),
                    paste0("Description = LUMP analysis database"),
                    paste0("Driver = ", odbc_driver),
                    paste0("ServerName = ", odbc_servername),
                    paste0("Database = ", output_dir, "/database/dbase.db"),
                    paste0(""))
      write(str_odbc, file="/users/stud06/tpilz/.odbc.ini", ncolumns=1, append=T, sep="\n")
      
      
      # create database sub-directory
      dir.create(paste(output_dir, "database", sep="/"))
      
      # create database
      db_create(db_name)
      
      # update database (if necessary)
      db_update(db_name)
      
      # create information file for filling landscape_units into database
      luout <- read.table(paste(output_dir, "lu.dat", sep="/"), header=T)
      lupar <- read.table(paste(output_dir, lupar_ofile, sep="/"), header=T)
      lupar$slopelength <- luout$x_length
      lupar$soil_depth <- -1 # groundwater option I.1.1 (WASA documentation) 
      lupar$allu_depth <- -1 # groundwater option I.1.1 (WASA documentation) 
      lupar$riverbed_depth <- 2000 # riverbed in any case below soil (no information whether this is reasonable or not)
      lupar$kf_bedrock <- -9999
      lupar$gw_dist <- -9999
      lupar$frgw_delay <- -9999
      write.table(lupar, paste(output_dir, "lu_db.dat", sep="/"), quote = F, row.names = F, sep="\t")
      
      # copy soil and vegetation parameter files into output_dir
      file.copy(paste(veg_path, "vegetation.dat", sep="/"), paste(output_dir, "vegetation.dat", sep="/"), overwrite=T)
      file.copy(paste(soil_path, "soil.dat", sep="/"), paste(output_dir, "soil.dat", sep="/"), overwrite=T)
      file.copy(paste(soil_path, "horizons.dat", sep="/"), paste(output_dir, "horizons.dat", sep="/"), overwrite=T)
      file.copy(paste(soil_path, "particle_classes.dat", sep="/"), paste(output_dir, "particle_classes.dat", sep="/"), overwrite=T)
      file.copy(paste(soil_path, "r_soil_contains_particles.dat", sep="/"), paste(output_dir, "r_soil_contains_particles.dat", sep="/"), overwrite=T)
      
      # LUMP output and manually prepared information (e.g. soil parameters) to database
      db_fill(dbname=db_name,
              tables = c("r_subbas_contains_lu", "subbasins",
                         "landscape_units", "r_lu_contains_tc", "terrain_components",
                         "r_tc_contains_svc", "vegetation", "soils", "horizons", "soil_veg_components",
                         "particle_classes", "r_soil_contains_particles", "rainy_season"),
              dat_files=c("lu_stats.txt", "sub_stats.txt", "lu_db.dat", "lucontainstc.dat",
                          "terraincomponents.dat", "tc_contains_svc.dat", "vegetation.dat",
                          "soil.dat", "horizons.dat", "soil_vegetation_components.dat",
                          "particle_classes.dat", "r_soil_contains_particles.dat", "rainy_season/rainy_season.csv"), 
              dat_dir=output_dir,
              overwrite=T, verbose=T)
      
      # Please process these cleaning actions step-by-step according to your needs.
      # Read the documentation first: ?db_check
      db_check(db_name, 
               check=c("filter_small_areas"), 
               option=list(area_thresh=0.01),
               fix=T,
               verbose=T)
      
      db_check(db_name, 
               check=c("tc_slope"), 
               option=list(treat_slope=c(3,0.01,0.1)),
               fix=T,
               verbose=T)
      
      # db_check(db_name, 
      #          check=c("special_areas"), 
      #          option=list(special_area = data.frame(reference_tbl=c("vegetation", "vegetation", "soils"), ref_id=c(3,4,10), special_id=c(1,1,2))),
      #          fix=F,
      #          verbose=F)
      
      db_check(db_name, 
               check=c("remove_water_svc"),
               fix=T,
               verbose=T)
      
      db_check(db_name, 
               check=c("compute_rocky_frac"),
               fix=T,
               verbose=T)
      
      db_check(db_name, 
               check=c("remove_impervious_svc"),
               fix=T,
               verbose=T)
      
      # db_check(db_name, 
      #          check=c("proxy_frgw_delay"), 
      #          option=list(total_mean_delay=50),
      #          fix=T,
      #          verbose=T)
      
      db_check(db_name,
               check=c("delete_obsolete"),
               fix=T,
               verbose=T)
      
      db_check(db_name,
               check=c("completeness"),
               fix=T,
               verbose=T)
      
      db_check(db_name,
               check=c("subbasin_order"),
               fix=T,
               verbose=T)
      
      
      
      # MODEL INPUT #
      db_wasa_input(dbname = db_name,
                    dest_dir = paste(output_dir, "WASA_input", sep="/"),
                    overwrite = overwrite, verbose=!silent)
      
      # adjust model input data #
      # create WASA simulation directory for current project
      dir.create(paste(wasa_sim_dir, dbname, sep="/"), recursive = T, showWarnings = F)
      dir.create(paste(wasa_sim_dir, dbname, "input", sep="/"), recursive = T, showWarnings = F)
      dir.create(paste(wasa_sim_dir, dbname, "output", sep="/"), recursive = T, showWarnings = F)
      
      # copy created WASA input data
      file.copy(paste(output_dir, "WASA_input/.", sep="/"), paste(wasa_sim_dir, dbname, "input", sep="/"), recursive = T, overwrite=T)
      
      # do.dat
      do_dat <- readLines(paste(wasa_sim_dir, dbname, "input", "do.dat", sep="/"))
      do_dat[2] <- "../input/"
      do_dat[3] <- "../output/"
      do_dat[4] <- paste0(sim_start[1], "\t//tstart (start year of simulation)")
      do_dat[5] <- paste0(sim_end[1], "\t//tstop (end year of simulation)")
      do_dat[6] <- paste0(sim_start[2], "\t//mstart (start month of simulation)")
      do_dat[7] <- paste0(sim_end[2], "\t//mstop (end month of simulation)")
      if(do_res_strategic)
        do_dat[14] <- ".t.\t//doreservoir: do reservoir calculations"
      if(do_res_lump)
        do_dat[15] <- ".t.\t//doacudes:includes dam calculations"
      if(save_wasa_states)
        do_dat[37] <- ".t.\t//save state of storages to files after simulation period (optional)"
      
      writeLines(do_dat, paste(wasa_sim_dir, dbname, "input", "do.dat", sep="/"))
      
      # output files
      write("This files describe which output files are generated", paste(wasa_sim_dir, dbname, "input", "outfiles.dat", sep="/"))
      write("put any character before the files you don't want to be created", paste(wasa_sim_dir, dbname, "input", "outfiles.dat", sep="/"), append=T)
      for (d in wasa_out_files)
        write(d, paste(wasa_sim_dir, dbname, "input", "outfiles.dat", sep="/"), append=T)
      
      # reservoir data
      # strategic reservoirs
      if(do_res_strategic) {
        # create directory
        dir.create(paste(wasa_sim_dir, dbname, "input", "Reservoir", sep="/"), recursive = T, showWarnings = F)
        # copy specified files into reservoir directory
        file.copy(paste(output_dir, "reservoir", "reservoir.dat", sep="/"), paste(wasa_sim_dir, dbname, "input", "Reservoir", "reservoir.dat", sep="/"))
        # cav file
        if(!is.null(cav_file))
          file.copy(cav_file, paste(wasa_sim_dir, dbname, "input", "Reservoir", "cav.dat", sep="/"))
      }
      # lumped reservoirs
      if(do_res_lump) {
        # create directory
        dir.create(paste(wasa_sim_dir, dbname, "input", "Reservoir", sep="/"), recursive = T, showWarnings = F)
        # copy specified files into reservoir directory
        file.copy(paste(output_dir, "reservoir", "lake.dat", sep="/"), paste(wasa_sim_dir, dbname, "input", "Reservoir", "lake.dat", sep="/"))
        file.copy(paste(output_dir, "reservoir", "lake_number.dat", sep="/"), paste(wasa_sim_dir, dbname, "input", "Reservoir", "lake_number.dat", sep="/"))
      }
      
      # time series (meteo) data
      dir.create(paste(wasa_sim_dir, dbname, "input", "Time_series", sep="/"), recursive = T, showWarnings = F)
      file.copy(paste(output_dir, "meteo/.", sep="/"), paste(wasa_sim_dir, dbname, "input", "Time_series", sep="/"), recursive = T)
      file.copy(radex_file, paste(wasa_sim_dir, dbname, "input", "Time_series", sep="/"))
      
    }) # measure pre-processing time
    
    # run WASA model
    if(!is.null(wasa_app)) {
      model_time <- system.time(cmd_out <- system(paste0(wasa_app, " ", wasa_sim_dir, "/", dbname, "/input/do.dat"), intern=TRUE))
      # write output to a log file
      writeLines(cmd_out, paste(wasa_sim_dir, dbname, "run.log", sep="/"))
    }
    
    
    
    # delete temporary R files (created by spgrass6 functions; flood disk within ensemble runs)
    system(paste0("find ", tempdir(), " -type f -mmin +60 -delete"))
    
    
    
  }, error = function(e) {
    
    stop(paste(e))  
    
  })
  
  # output to be combined
  run_times <- t(c(prep_time["elapsed"], model_time["elapsed"]))
  rownames(run_times) <- dbname
  colnames(run_times) <- c("preprocessing", "model_runtime")
  run_times
  
} # loop over combinations of crucial landscape discretisation parameters

write.table(logdata, "../runtimes_1.log", quote=F, sep="\t")

 
